{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Assignment - Web3 Trading Team\n",
    "\n",
    "## Analysis of Trader Behavior vs Market Sentiment\n",
    "\n",
    "This notebook analyzes the relationship between trading behavior and market sentiment using:\n",
    "1. **Bitcoin Market Sentiment Dataset** - Fear/Greed Index\n",
    "2. **Historical Trader Data from Hyperliquid** - Trading transactions\n",
    "\n",
    "### Objective\n",
    "Analyze how trading behavior (profitability, risk, volume, leverage) aligns or diverges from overall market sentiment (fear vs greed). Identify hidden trends or signals that could influence smarter trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn plotly scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Note: Upload the CSV files to Colab first\n",
    "\n",
    "# Load fear/greed index data\n",
    "sentiment_df = pd.read_csv('fear_greed_index.csv')\n",
    "print(\"Fear/Greed Index Data Shape:\", sentiment_df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(sentiment_df.head())\n",
    "\n",
    "# Load historical trading data\n",
    "trading_df = pd.read_csv('historical_data.csv')\n",
    "print(\"\\nTrading Data Shape:\", trading_df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(trading_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the datasets\n",
    "print(\"=== FEAR/GREED INDEX DATA INFO ===\")\n",
    "print(sentiment_df.info())\n",
    "print(\"\\n=== TRADING DATA INFO ===\")\n",
    "print(trading_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=== MISSING VALUES IN FEAR/GREED DATA ===\")\n",
    "print(sentiment_df.isnull().sum())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES IN TRADING DATA ===\")\n",
    "print(trading_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to datetime\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "sentiment_df['timestamp'] = pd.to_datetime(sentiment_df['timestamp'], unit='s')\n",
    "\n",
    "# Convert trading data timestamps - FIXED FORMAT\n",
    "trading_df['Timestamp IST'] = pd.to_datetime(trading_df['Timestamp IST'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Handle the second timestamp column more carefully\n",
    "try:\n",
    "    trading_df['Timestamp'] = pd.to_datetime(trading_df['Timestamp'], unit='s')\n",
    "except:\n",
    "    # If seconds conversion fails, try milliseconds\n",
    "    try:\n",
    "        trading_df['Timestamp'] = pd.to_datetime(trading_df['Timestamp'], unit='ms')\n",
    "    except:\n",
    "        # If that fails too, just use the IST timestamp\n",
    "        trading_df['Timestamp'] = trading_df['Timestamp IST']\n",
    "\n",
    "print(\"Date ranges:\")\n",
    "print(f\"Sentiment data: {sentiment_df['date'].min()} to {sentiment_df['date'].max()}\")\n",
    "print(f\"Trading data: {trading_df['Timestamp IST'].min()} to {trading_df['Timestamp IST'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare trading data\n",
    "# Convert numeric columns\n",
    "numeric_columns = ['Execution Price', 'Size Tokens', 'Size USD', 'Start Position', 'Closed PnL', 'Fee']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in trading_df.columns:\n",
    "        trading_df[col] = pd.to_numeric(trading_df[col], errors='coerce')\n",
    "\n",
    "# Create additional trading metrics\n",
    "trading_df['Trade_Value'] = trading_df['Size USD']\n",
    "trading_df['Is_Buy'] = (trading_df['Side'] == 'BUY').astype(int)\n",
    "trading_df['Is_Sell'] = (trading_df['Side'] == 'SELL').astype(int)\n",
    "\n",
    "# Calculate daily trading metrics\n",
    "daily_trading = trading_df.groupby(trading_df['Timestamp IST'].dt.date).agg({\n",
    "    'Trade_Value': ['sum', 'mean', 'count'],\n",
    "    'Closed PnL': ['sum', 'mean'],\n",
    "    'Is_Buy': 'sum',\n",
    "    'Is_Sell': 'sum',\n",
    "    'Fee': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "daily_trading.columns = ['Total_Volume', 'Avg_Trade_Size', 'Trade_Count', 'Total_PnL', 'Avg_PnL', 'Buy_Count', 'Sell_Count', 'Total_Fees']\n",
    "daily_trading = daily_trading.reset_index()\n",
    "daily_trading['Date'] = pd.to_datetime(daily_trading['Timestamp IST'])\n",
    "\n",
    "print(\"Daily trading metrics shape:\", daily_trading.shape)\n",
    "display(daily_trading.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sentiment_counts = sentiment_df['classification'].value_counts()\n",
    "plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Market Sentiment')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sentiment_df['value'], bins=30, alpha=0.7, color='skyblue')\n",
    "plt.xlabel('Fear/Greed Index Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Fear/Greed Index Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/sentiment_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trading behavior\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(daily_trading['Total_Volume'], bins=30, alpha=0.7, color='green')\n",
    "plt.xlabel('Daily Trading Volume (USD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Daily Trading Volume')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(daily_trading['Total_PnL'], bins=30, alpha=0.7, color='orange')\n",
    "plt.xlabel('Daily PnL (USD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Daily PnL')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(daily_trading['Buy_Count'], daily_trading['Sell_Count'], alpha=0.6)\n",
    "plt.xlabel('Buy Count')\n",
    "plt.ylabel('Sell Count')\n",
    "plt.title('Buy vs Sell Count Relationship')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(daily_trading['Total_Volume'], daily_trading['Total_PnL'], alpha=0.6)\n",
    "plt.xlabel('Total Volume')\n",
    "plt.ylabel('Total PnL')\n",
    "plt.title('Volume vs PnL Relationship')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/trading_behavior_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment over time\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create color mapping for sentiment\n",
    "sentiment_colors = {\n",
    "    'Extreme Fear': 'darkred',\n",
    "    'Fear': 'red',\n",
    "    'Neutral': 'yellow',\n",
    "    'Greed': 'green',\n",
    "    'Extreme Greed': 'darkgreen'\n",
    "}\n",
    "\n",
    "plt.scatter(sentiment_df['date'], sentiment_df['value'], \n",
    "           c=sentiment_df['classification'].map(sentiment_colors), \n",
    "           alpha=0.6, s=20)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Fear/Greed Index Value')\n",
    "plt.title('Bitcoin Market Sentiment Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                              markerfacecolor=color, markersize=8, label=label)\n",
    "                  for label, color in sentiment_colors.items()]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/sentiment_over_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge Sentiment with Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sentiment data with daily trading data\n",
    "sentiment_daily = sentiment_df.groupby(sentiment_df['date'].dt.date).agg({\n",
    "    'value': 'mean',\n",
    "    'classification': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Neutral'\n",
    "}).reset_index()\n",
    "sentiment_daily['Date'] = pd.to_datetime(sentiment_daily['date'])\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = pd.merge(daily_trading, sentiment_daily, on='Date', how='inner')\n",
    "\n",
    "print(\"Merged dataset shape:\", merged_data.shape)\n",
    "print(\"\\nSample of merged data:\")\n",
    "display(merged_data.head())\n",
    "\n",
    "# Save merged data\n",
    "merged_data.to_csv('csv_files/merged_sentiment_trading.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading Behavior by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trading metrics by sentiment\n",
    "sentiment_analysis = merged_data.groupby('classification').agg({\n",
    "    'Total_Volume': ['mean', 'std', 'count'],\n",
    "    'Total_PnL': ['mean', 'std'],\n",
    "    'Trade_Count': ['mean', 'std'],\n",
    "    'Buy_Count': 'mean',\n",
    "    'Sell_Count': 'mean',\n",
    "    'Total_Fees': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Trading Behavior by Market Sentiment:\")\n",
    "display(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trading behavior by sentiment\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Volume by sentiment\n",
    "sentiment_volume = merged_data.groupby('classification')['Total_Volume'].mean().sort_values(ascending=False)\n",
    "axes[0, 0].bar(sentiment_volume.index, sentiment_volume.values, color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "axes[0, 0].set_title('Average Daily Trading Volume by Sentiment')\n",
    "axes[0, 0].set_ylabel('Volume (USD)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# PnL by sentiment\n",
    "sentiment_pnl = merged_data.groupby('classification')['Total_PnL'].mean().sort_values(ascending=False)\n",
    "axes[0, 1].bar(sentiment_pnl.index, sentiment_pnl.values, color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "axes[0, 1].set_title('Average Daily PnL by Sentiment')\n",
    "axes[0, 1].set_ylabel('PnL (USD)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Trade count by sentiment\n",
    "sentiment_trades = merged_data.groupby('classification')['Trade_Count'].mean().sort_values(ascending=False)\n",
    "axes[1, 0].bar(sentiment_trades.index, sentiment_trades.values, color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "axes[1, 0].set_title('Average Daily Trade Count by Sentiment')\n",
    "axes[1, 0].set_ylabel('Number of Trades')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Buy/Sell ratio by sentiment\n",
    "merged_data['Buy_Sell_Ratio'] = merged_data['Buy_Count'] / (merged_data['Buy_Count'] + merged_data['Sell_Count'])\n",
    "sentiment_ratio = merged_data.groupby('classification')['Buy_Sell_Ratio'].mean().sort_values(ascending=False)\n",
    "axes[1, 1].bar(sentiment_ratio.index, sentiment_ratio.values, color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "axes[1, 1].set_title('Buy/Sell Ratio by Sentiment')\n",
    "axes[1, 1].set_ylabel('Buy Ratio')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/trading_by_sentiment.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "correlation_data = merged_data[['value', 'Total_Volume', 'Total_PnL', 'Trade_Count', 'Buy_Count', 'Sell_Count', 'Total_Fees']]\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Sentiment vs Trading Metrics')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Perform statistical tests\n",
    "print(\"=== STATISTICAL ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. ANOVA test for PnL across different sentiments\n",
    "sentiment_groups = [merged_data[merged_data['classification'] == sent]['Total_PnL'] \n",
    "                   for sent in ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']]\n",
    "f_stat, p_value = stats.f_oneway(*sentiment_groups)\n",
    "print(f\"ANOVA test for PnL across sentiments:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\\n\")\n",
    "\n",
    "# 2. Correlation test between sentiment and volume\n",
    "corr_coef, p_value = stats.pearsonr(merged_data['value'], merged_data['Total_Volume'])\n",
    "print(f\"Correlation between sentiment and volume:\")\n",
    "print(f\"Correlation coefficient: {corr_coef:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant correlation: {'Yes' if p_value < 0.05 else 'No'}\\n\")\n",
    "\n",
    "# 3. Correlation test between sentiment and PnL\n",
    "corr_coef, p_value = stats.pearsonr(merged_data['value'], merged_data['Total_PnL'])\n",
    "print(f\"Correlation between sentiment and PnL:\")\n",
    "print(f\"Correlation coefficient: {corr_coef:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant correlation: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "print(\"=== KEY INSIGHTS ===\\n\")\n",
    "\n",
    "# Best performing sentiment\n",
    "best_sentiment = merged_data.groupby('classification')['Total_PnL'].mean().idxmax()\n",
    "best_pnl = merged_data.groupby('classification')['Total_PnL'].mean().max()\n",
    "print(f\"1. Best performing sentiment: {best_sentiment} (Avg PnL: ${best_pnl:.2f})\")\n",
    "\n",
    "# Highest volume sentiment\n",
    "highest_volume_sentiment = merged_data.groupby('classification')['Total_Volume'].mean().idxmax()\n",
    "highest_volume = merged_data.groupby('classification')['Total_Volume'].mean().max()\n",
    "print(f\"2. Highest trading volume: {highest_volume_sentiment} (Avg Volume: ${highest_volume:.2f})\")\n",
    "\n",
    "# Most volatile sentiment\n",
    "most_volatile = merged_data.groupby('classification')['Total_PnL'].std().idxmax()\n",
    "volatility = merged_data.groupby('classification')['Total_PnL'].std().max()\n",
    "print(f\"3. Most volatile sentiment: {most_volatile} (Std Dev: ${volatility:.2f})\")\n",
    "\n",
    "# Risk-adjusted returns\n",
    "risk_adjusted = merged_data.groupby('classification').apply(\n",
    "    lambda x: x['Total_PnL'].mean() / x['Total_PnL'].std() if x['Total_PnL'].std() > 0 else 0\n",
    ").sort_values(ascending=False)\n",
    "best_risk_adjusted = risk_adjusted.idxmax()\n",
    "print(f\"4. Best risk-adjusted returns: {best_risk_adjusted} (Sharpe-like ratio: {risk_adjusted.max():.3f})\")\n",
    "\n",
    "# Trading frequency by sentiment\n",
    "trading_frequency = merged_data.groupby('classification')['Trade_Count'].mean().sort_values(ascending=False)\n",
    "most_active = trading_frequency.idxmax()\n",
    "print(f\"5. Most active trading sentiment: {most_active} (Avg trades: {trading_frequency.max():.1f})\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(\"1. Consider sentiment-based position sizing\")\n",
    "print(\"2. Implement sentiment-aware risk management\")\n",
    "print(\"3. Monitor sentiment transitions for entry/exit signals\")\n",
    "print(\"4. Develop sentiment-based trading strategies\")\n",
    "print(\"5. Use sentiment data for portfolio diversification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "print(\"Saving analysis results...\")\n",
    "\n",
    "# Save processed data\n",
    "merged_data.to_csv('csv_files/final_analysis_data.csv', index=False)\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'Total_Days_Analyzed': len(merged_data),\n",
    "    'Date_Range': f\"{merged_data['Date'].min()} to {merged_data['Date'].max()}\",\n",
    "    'Total_Trading_Volume': merged_data['Total_Volume'].sum(),\n",
    "    'Total_PnL': merged_data['Total_PnL'].sum(),\n",
    "    'Total_Trades': merged_data['Trade_Count'].sum(),\n",
    "    'Sentiment_Categories': merged_data['classification'].nunique(),\n",
    "    'Best_Performing_Sentiment': best_sentiment,\n",
    "    'Highest_Volume_Sentiment': highest_volume_sentiment,\n",
    "    'Most_Volatile_Sentiment': most_volatile,\n",
    "    'Best_Risk_Adjusted_Sentiment': best_risk_adjusted\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(list(summary_stats.items()), columns=['Metric', 'Value'])\n",
    "summary_df.to_csv('csv_files/analysis_summary.csv', index=False)\n",
    "\n",
    "print(\"Analysis complete! Check the outputs/ directory for visualizations.\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"- csv_files/final_analysis_data.csv\")\n",
    "print(\"- csv_files/analysis_summary.csv\")\n",
    "print(\"- outputs/ (various visualization files)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}